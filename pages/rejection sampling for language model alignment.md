- RFT 是一种基于拒绝采样的迭代自我改进方法，**核心思想是：让模型自己生成答案，然后筛选出高质量答案用于下一轮训练，实现"自我进化"。**
- 让模型自己生成多个答案 → 筛选出正确答案 → 用正确答案继续训练模型 → 迭代循环。
  **这种方法不需要人工标注新数据，也不需要训练复杂的奖励模型**，特别适合答案可验证的任务（如数学推理、代码生成）。
-
- ![RFT工作流程.png](../assets/RFT工作流程_1770627193438_0.png)
- | 组件       | 说明                                   |
  | -------- | ------------------------------------ |
  | **采样策略** | 使用温度采样或 nucleus sampling 生成多样化答案     |
  | **筛选标准** | 答案正确性（可验证任务）、奖励模型打分、一致性检查            |
  | **训练目标** | 标准 SFT (Supervised Fine-Tuning) 损失函数 |
  | **迭代机制** | 多轮循环，每轮用上一轮优化后的模型生成新数据               |
-
-
-